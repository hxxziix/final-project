- yolo 개념 공부 및 roboflow에 업로드된 임의의 메타 데이터로 실습하였다.

- 로컬 환경에서 모델을 학습 시키는 시간을 줄이기 위해 cpu 대신 gpu 연산을 
  활용하고자 cuda, cudnn, torch 설치하였다.

- 수집한 두개의 데이터셋이 있었는데 하나는 라벨링이 되있었고 하나는 안되어 
  있었다.

- 라벨링이 안되어 있는 데이터는 train 이미지만 존재했었다, 그래서 이미지 
  개수를 train : test = 7 : 3 으로 분할한 다음
  train : valid = 7 : 3 으로 분리하고, 마무리로 train, valid, test 각각 labels 폴더를 만들고 그 안에 직접 라벨링 해준 텍스트파일을 넣었다.

- 이 후 이 두 개의 데이터셋을 합치기로 했다, 중복되는 클래스를 하나의 
  클래스 번호로 통일하고
  중복되지 않는 클래스 번호는 한 데이터의 마지막 클래스 번호 다음 순서로 매겨주는 식으로 yaml파일을 만들어주었다.

- 파인튜닝이 끝난 후 테스트 이미지들을 model.predict 해보았다.

- 이제는 정적인 이미지 예측 대신에 웹캠 화면을 통한 실시간 프레임단위의 
  이미지를 인식해 보고자
  opencv 이미지 처리 기술을 활용해 웹캠 화면을 프레임단위로 나누고 그 프레임에서 인식된 객체의 정보(박스, 객체 이름, 신뢰도)를
  프레임 이미지 객체 위치에 표시하여 보여주는 식으로 코드를 작성했다.

- 우리의 모델을 가지고 웹캠 인식 테스트를 해보았을때 인식되는 객체도 있었고 
  다르게 인식하는 객체도 있었다.

- 그래서 모델의 성능을 높일 방법을 생각해보았고, 해결책은 더 다양한 
  데이터가 훈련된 모델을 만들고자 했다.

- 그러나 더 많은 데이터셋을 구하기는 했지만 이 데이터셋들을 합치려면   
  중복되는 클래스를 통합하고 야몰파일을 재정의 해야하는 번거로움이 있었다.

- 문득 생각난것이 그냥 각 데이터셋마다 파인튜닝된 모델을 만들고 그 모델들을 
  합칠 방법이 없는지 궁금해서 정보를 찾아봤더니
  여러 모델을 하나로 결합하는것은 딥러닝 분야에서 흥미로운 주제였고, 유명한 방법중 하나인 앙상블 기법을 접해보았다.

- 각 데이터셋마다 파인튜닝된 모델을 만들었다, 여기서 각 모델들을 파인튜닝할 
  때 입력 이미지 사이즈를 통일해주었다.
  각 모델마다 동일한 해상도에서 예측이 수행되어야 예측들을 비교하기 편하기 떄문이다.
  주로 사전학습된 yolov9s 모델로 파인튜닝을 진행하였고, 모든 모델들을 model.train 매개변수에 batch 16, imgsz 640 값을 넣어주었다.

- 이후 완성된 모델들을 모아서 로드해주고 앙상블 기법중 한가지를   
  사용해보았다.
  이 모델들로 객체를 인식하는 최종적인 방식인 Non-Maximum Suppression 알고리즘이다.

- NMS란
  동일 객체에 대해 여러 개의 바운딩 박스가 탐지되었을 때 중복을 제거하고, 이 기법은 각 박스의 신뢰도(confidence)를 기준으로 가장 신뢰도가 높은 박스를 선택하고, 중복되는 박스는 제거하는 방식이다.

- 그러나 NMS 방식에서 문제가 있었다, 여러개의 모델중 과적합 훈련된 모델이 
  일부 있을경우 틀린 예측을 하는 반면, 신뢰도도 매우 높게 나와서
  해당 바인딩 박스와 신뢰도, 라벨이 채택이 되어버린다.

- 나머지 다수의 모델들은 신뢰도가 일부 소수의 과적합 모델의 신뢰도보다 살짝 
  낮지만 객체는 올바르게 인식하였다.

- 그래서 앙상블 기법중 다른 알고리즘인 다수결 방식이란 것을 사용했다.

- 다수결 방식이란
  
  모든 박스를 서로 한 쌍씩 겹침 정도의 비율, 즉 iou를 계산하고,(iou는 두 박스 영역의 교집합을 합집합으로 나눈값이다.) iou를 1에서 뺀 값이 특정 수치보다 작으면 많이 겹쳤다고 판단한다, 왜냐하면 iou는 겹침 정도의 비율이 클수록 1에서 뺀 값이 작아지기 때문이다.

  다음으로 서로 많이 겹쳐진 박스들끼리 그룹화 한다.

  각 그룹에서 박스들의 좌표의 평균을 최종 박스 좌표로 결정한다.(박스의 좌표는 우상단과 좌상단 두 꼭짓점의 좌표를 말한다.)

  각 그룹에서 박스들의 신뢰도의 평균을 최종 신뢰도로 결정한다.

  각 그룹에서 박스들의 라벨 이름중 빈도수가 높은것을 최종 라벨 이름으로 결정한다.(다수결)

  이미지에 최종 박스 좌표 위치에 사각형을 그리고, 신뢰도와 라벨 이름을 텍스트로 표시한다.

- 다수결 방식에도 일부 과적합 모델이 말썽이었다.
  
  다음과 같이 조건을 추가하였다.

### 각 모델들이 감지한 객체의 수
**ex) detection_counts**:

**[1, 2, 2, 0, 1, 1, 0, 1, 0, 0, 0]**

총 8개의 객체 감지, 바운딩된 박스의 수: 8개

### 1. 겹치는 박스끼리 박스의 번호로 그룹화(서로 겹치는 정도가 특정 기준 수치보다 커야 그룹을 이룸)
**groups**:

**[[0], [1], [2, 4, 7], [3, 6], [5]]**

바운딩된 박스중 3개가 서로 겹치고 2개가 서로 겹침, 나머지는 단일 박스

### 2. 조건1: 적어도 박스가 3개이상 겹치는 그룹만 1차 통과
**[[2, 4, 7]]**

만약 3개이상 겹치는 그룹이 없다면
박스, 신뢰도, 라벨 모두 빈 리스트를 반환하고 화면에 표시하지 않음

### 3. 그룹에서 각 박스의 라벨을 추출하고, 각 라벨의 빈도수 조사
**['carrot', 'carrot', 'tofu']**

### 4. 조건2: 빈도수가 가장 높은 라벨은 그 수치가 2 이상이어야 최종 통과됨
**carrot**

그러나 만약 그룹의 라벨들이 다음과 같다면

**['carrot', 'apple', 'tofu']**

빈도수가 모두 1이므로 여기서는 NMS 방식을 적용해 신뢰도가 가장 높은 박스의 정보를 반환한다.

이번엔 라벨 빈도수 최빈값이 1보다 크고, 빈도수가 가장 큰 라벨이 여러 개인 경우이다.

**['carrot', 'carrot', 'apple', 'apple', 'tofu']**

이 경우엔 최빈값이 2이고, 최빈값이 2에 해당하는 박스들끼리만 NMS를 적용한다.

즉, 최빈값이 1보다 큰 경우는 공통 최빈값을 갖는 박스들끼리만, 최빈값이 1인 경우는 모든 박스들을 NMS를 적용한다.


- 이러한 방식으로 웹캠 화면에서 테스트를 마친 이후 다음 단계는 인식된 
  객체가 담긴 집합(객체가 중복되지 않게 리스트 대신 집합 채택)을 가지고 레시피 데이터셋에서 재료가 담긴 열을 조건문으로 불린참조하여 조건에 맞는 행에 담긴 정보를 가지고 사용자에게 정보를 제시해볼 생각이다.

- 최종적으로 이것들을 종합해서 웹사이트에서 서비스할 생각이다.(사이트 
  구현은 streamlit 사용해볼 예정)

